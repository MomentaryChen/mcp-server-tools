import { Kafka, logLevel } from "kafkajs";
import { McpServer } from "@modelcontextprotocol/sdk/server/mcp.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import { z } from "zod";

function parseArgs() {
  const args = process.argv.slice(2);
  const config = {
    brokers: [],
    topics: [],
    groupId: `mcp-kafka-${Math.random().toString(16).slice(2, 8)}`,
    clientId: `mcp-kafka-client-${Math.random().toString(16).slice(2, 8)}`,
    fromBeginning: false,
    username: null,
    password: null,
    useSsl: false
  };

  for (let i = 0; i < args.length; i++) {
    const arg = args[i];
    switch (arg) {
      case "--brokers":
        config.brokers = args[++i]
          .split(",")
          .map((b) => b.trim())
          .filter(Boolean)
          .map((b) => (b.includes(":") ? b : `${b}:9092`)); // è‹¥æœªæŒ‡å®šç«¯å£ï¼Œè£œä¸Š Kafka é è¨­ 9092
        break;
      case "--topics":
        config.topics.push(...args[++i].split(",").map((t) => t.trim()).filter(Boolean));
        break;
      case "--group-id":
        config.groupId = args[++i];
        break;
      case "--client-id":
        config.clientId = args[++i];
        break;
      case "--from-beginning":
        config.fromBeginning = true;
        break;
      case "--username":
        config.username = args[++i];
        break;
      case "--password":
        config.password = args[++i];
        break;
      case "--ssl":
        config.useSsl = true;
        break;
    }
  }

  return config;
}

const config = parseArgs();

if (config.brokers.length === 0) {
  console.error("âŒ å¿…é ˆæä¾› --brokersï¼Œä¾‹å¦‚ï¼šlocalhost:9092,localhost:9093");
  process.exit(1);
}

const kafka = new Kafka({
  clientId: config.clientId,
  brokers: config.brokers,
  ssl: config.useSsl || undefined,
  sasl: config.username
    ? {
        mechanism: "plain",
        username: config.username,
        password: config.password ?? ""
      }
    : undefined,
  logLevel: logLevel.ERROR
});

const producer = kafka.producer();
const consumer = kafka.consumer({ groupId: config.groupId });
let producerConnected = false;
let consumerConnected = false;
let consumerRunning = false;

const messageStore = [];
const maxMessages = 10000;

async function ensureConnections() {
  if (!producerConnected) {
    await producer.connect();
    producerConnected = true;
    console.error("âœ… Kafka Producer å·²é€£ç·š");
  }

  if (!consumerConnected) {
    await consumer.connect();
    consumerConnected = true;
    console.error("âœ… Kafka Consumer å·²é€£ç·š");
  }
}

async function stopConsumerLoop() {
  if (!consumerRunning) return;
  try {
    await consumer.stop();
    consumerRunning = false;
    console.error("â¹ï¸ Kafka Consumer å·²åœæ­¢");
  } catch (err) {
    console.error(`âŒ åœæ­¢ Consumer å¤±æ•—: ${err.message}`);
  }
}

async function startConsumerLoop() {
  if (consumerRunning) return;
  consumerRunning = true;

  await consumer.run({
    eachMessage: async ({ topic, partition, message }) => {
      const record = {
        topic,
        partition,
        offset: message.offset,
        timestamp: new Date(Number(message.timestamp)).toISOString(),
        key: message.key?.toString() ?? null,
        value: message.value?.toString() ?? "",
        headers: message.headers
          ? Object.fromEntries(
              Object.entries(message.headers).map(([k, v]) => [k, v?.toString() ?? ""])
            )
          : {}
      };

      messageStore.push(record);
      if (messageStore.length > maxMessages) {
        messageStore.shift();
      }

      console.error(
        `ğŸ“¥ æ”¶åˆ°æ¶ˆæ¯ topic=${topic} partition=${partition} offset=${record.offset} key=${record.key}`
      );
    }
  });

  console.error("â–¶ï¸ Kafka Consumer é–‹å§‹æ‹‰å–æ¶ˆæ¯");
}

const server = new McpServer({ name: "kafka-tools", version: "1.0.0" });

server.tool(
  "kafka_status",
  {},
  async () => ({
    content: [
      {
        type: "text",
        text: JSON.stringify(
          {
            producerConnected,
            consumerConnected,
            consumerRunning,
            brokers: config.brokers,
            topics: config.topics,
            groupId: config.groupId,
            clientId: config.clientId,
            useSsl: config.useSsl,
            saslUser: config.username ?? undefined,
            messageCount: messageStore.length
          },
          null,
          2
        )
      }
    ]
  })
);

server.tool(
  "kafka_publish",
  {
    topic: z.string(),
    message: z.string(),
    key: z.string().optional(),
    headers: z.record(z.string(), z.string()).optional(),
    partition: z.number().optional()
  },
  async ({ topic, message, key, headers = {}, partition }) => {
    try {
      await ensureConnections();

      await producer.send({
        topic,
        messages: [
          {
            value: message,
            key,
            headers,
            partition
          }
        ]
      });

      return {
        content: [
          {
            type: "text",
            text: `æ¶ˆæ¯å·²é€å‡º topic=${topic}${partition !== undefined ? ` partition=${partition}` : ""}`
          }
        ]
      };
    } catch (err) {
      return {
        content: [{ type: "text", text: `ç™¼å¸ƒå¤±æ•—: ${err.message}` }],
        isError: true
      };
    }
  }
);

server.tool(
  "kafka_subscribe",
  {
    topic: z.string(),
    fromBeginning: z.boolean().optional()
  },
  async ({ topic, fromBeginning = config.fromBeginning }) => {
    try {
      await ensureConnections();

      if (config.topics.includes(topic)) {
        return { content: [{ type: "text", text: `å·²ç¶“è¨‚é–± topic=${topic}` }] };
      }

      // å¦‚æœæ¶ˆè²»è€…æ­£åœ¨é‹è¡Œï¼Œéœ€è¦å…ˆåœæ­¢å†é‡æ–°è¨‚é–±æ‰€æœ‰ topics
      const wasRunning = consumerRunning;
      if (wasRunning) {
        await stopConsumerLoop();
      }

      // æ·»åŠ æ–°çš„ topic åˆ°é…ç½®
      config.topics.push(topic);

      // é‡æ–°è¨‚é–±æ‰€æœ‰ topicsï¼ˆåŒ…æ‹¬æ–°çš„ï¼‰
      await consumer.subscribe({
        topics: config.topics,
        fromBeginning
      });
      console.error(`âœ… å·²è¨‚é–± Kafka topic=${topic} fromBeginning=${fromBeginning}`);

      // é‡æ–°å•Ÿå‹•æ¶ˆè²»è€…
      await startConsumerLoop();

      return {
        content: [{ type: "text", text: `æˆåŠŸè¨‚é–± topic=${topic} fromBeginning=${fromBeginning}` }]
      };
    } catch (err) {
      return {
        content: [{ type: "text", text: `è¨‚é–±å¤±æ•—: ${err.message}` }],
        isError: true
      };
    }
  }
);

server.tool(
  "kafka_get_messages",
  {
    limit: z.number().optional(),
    topic: z.string().optional(),
    partition: z.number().optional()
  },
  async ({ limit = 10, topic, partition }) => {
    try {
      let messages = [...messageStore];

      if (topic) {
        messages = messages.filter((m) => m.topic === topic);
      }
      if (partition !== undefined) {
        messages = messages.filter((m) => m.partition === partition);
      }

      messages = messages.slice(-limit);

      return {
        content: [
          {
            type: "text",
            text: JSON.stringify(messages, null, 2)
          }
        ]
      };
    } catch (err) {
      return {
        content: [{ type: "text", text: `ç²å–æ¶ˆæ¯å¤±æ•—: ${err.message}` }],
        isError: true
      };
    }
  }
);

server.tool(
  "kafka_clear_messages",
  {},
  async () => {
    const count = messageStore.length;
    messageStore.length = 0;
    return {
      content: [{ type: "text", text: `å·²æ¸…ç©º ${count} æ¢ç·©å­˜æ¶ˆæ¯` }]
    };
  }
);

async function bootstrap() {
  try {
    await ensureConnections();

    if (config.topics.length > 0) {
      for (const topic of config.topics) {
        await consumer.subscribe({ topic, fromBeginning: config.fromBeginning });
        console.error(`âœ… é è¨­è¨‚é–± topic=${topic} fromBeginning=${config.fromBeginning}`);
      }
      await startConsumerLoop();
    } else {
      console.error("â„¹ï¸ æœªæŒ‡å®šé è¨­ topicï¼Œå¯é€é kafka_subscribe å‹•æ…‹è¨‚é–±");
    }

    const transport = new StdioServerTransport();
    await server.connect(transport);
    console.error("âœ… MCP Kafka Server å·²å•Ÿå‹•");
  } catch (err) {
    console.error("âŒ Kafka æœå‹™å•Ÿå‹•å¤±æ•—:", err);
    process.exit(1);
  }
}

await bootstrap();

